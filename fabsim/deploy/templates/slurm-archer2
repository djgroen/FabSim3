#!/bin/bash
## slurm-archer2
## number of nodes
#SBATCH --nodes=$nodes

#SBATCH --ntasks-per-node=$taskspernode

#SBATCH --cpus-per-task=$cpuspertask

## wall time in format MINUTES:SECONDS
#SBATCH --time=$job_wall_time

## grant
#SBATCH --account=$budget

## stdout file
#SBATCH --output=$job_results/JobID-%j.output

## stderr file
#SBATCH --error=$job_results/JobID-%j.error

## Set the initial working directory to work filesystem (fixes the warning!)
#SBATCH --chdir=$job_results

#SBATCH --partition=$partition_name
#SBATCH --qos=$qos_name

# Set the number of threads to 1 (prevents automatic threading)
export OMP_NUM_THREADS=1

# Ensure the cpus-per-task option is propagated to srun commands
export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK

# Important for resource awareness
export SLURM_NTASKS=$((SLURM_JOB_NUM_NODES * SLURM_NTASKS_PER_NODE))

