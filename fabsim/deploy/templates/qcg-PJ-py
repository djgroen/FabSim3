#!/usr/bin/env python3
"""
FabSim3 QCG-PilotJob manager script - automatically generated
Controls the execution of tasks through QCG-PilotJob
"""
import logging
import sys
import time

from qcg.pilotjob.api.job import Jobs
from qcg.pilotjob.api.manager import LocalManager

# Set up logging with WARNING level for most logs
# Only our direct logger will use INFO
logging.basicConfig(
    level=logging.WARNING,  # Change the base level to WARNING
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)

# Create our logger with a higher level
logger = logging.getLogger("QCG_Manager")
logger.setLevel(logging.INFO)

# Record start time for performance tracking
start_time = time.time()

try:
    # Initialize QCG-PilotJob manager with more controlled logging
    logger.info("Initializing QCG-PilotJob manager with nodes=${QCG_PJ_NODES}, cores=${QCG_PJ_TOTAL_CORES}")
    manager = LocalManager(cfg={
        'log_level': 'error',
        'log_file': 'qcg_service.log',
        'report_format': 'json',
        'scheduler': {
            'constraints': {
                'nodes': ${QCG_PJ_NODES},
                'cores': ${QCG_PJ_TOTAL_CORES},
                'binding': False  # Disable strict core binding to avoid mismatch
            }
        },
        'show_progress': True,
        'enable_proc_stats': False,
        'enable_rt_stats': False,
        'system_core': False,  # Explicitly inform about hyperthreaded cores
    })
    
    # Verify detected resources
    resources = manager.resources()
    logger.info(f"Detected resources: {resources.get('total_cores', 'N/A')} cores, "
                f"{resources.get('nodes', 'N/A')} nodes")

    # Create jobs collection and add tasks
    jobs = Jobs()
    
    # TASK DESCRIPTION BLOCK START
$JOB_DESCRIPTIONS
    # TASK DESCRIPTION BLOCK END

    # Submit all jobs to QCG-PilotJob
    logger.info("Submitting jobs to QCG-PilotJob")
    ids = manager.submit(jobs)
    
    # Count number of job IDs
    job_count = len(ids) if ids else 0
    logger.info(f"Submitted {job_count} jobs")
    
    # Wait for jobs to complete with minimal progress updates
    logger.info("Waiting for jobs to complete...")
    completion_start = time.time()
    
    # Simplified progress tracking with less frequent updates
    total_jobs = len(ids)
    last_reported_percentage = -1
    
    # Use standard blocking wait with timeout
    try:
        # Wait for all jobs with timeout (50 hours)
        manager.wait4(ids, timeout=180000)
        logger.info("All jobs completed successfully")
    except Exception as e:
        # If wait fails, check final status
        try:
            job_info = manager.info(ids)
            completed_jobs = sum(1 for job in job_info.values() 
                               if job.get('status') in ['SUCCEED', 'FAILED'])
            failed_jobs = sum(1 for job in job_info.values() 
                            if job.get('status') == 'FAILED')
            
            if completed_jobs == total_jobs:
                logger.info("All jobs completed")
                if failed_jobs > 0:
                    logger.warning(f"{failed_jobs} jobs failed")
            else:
                logger.error(f"Only {completed_jobs}/{total_jobs} jobs completed")
        except:
            logger.error(f"Error during job execution: {e}")
    
    completion_time = time.time() - completion_start
    
    # Brief summary
    logger.info(f"Execution completed in {completion_time:.1f} seconds")
    
    # Clean shutdown
    manager.finish()
        
except Exception as e:
    logger.error(f"Error in QCG-PilotJob execution: {str(e)}")
    if hasattr(e, '__traceback__'):
        import traceback
        logger.error(traceback.format_exc())
    
    # Try to clean up if manager exists
    if 'manager' in locals():
        try:
            manager.finish()
        except:
            pass
    
    sys.exit(1)
